{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport math\nimport random","metadata":{"id":"7Z4TC5vl5OlA","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:48.044964Z","iopub.execute_input":"2025-11-05T20:16:48.045180Z","iopub.status.idle":"2025-11-05T20:16:51.542973Z","shell.execute_reply.started":"2025-11-05T20:16:48.045158Z","shell.execute_reply":"2025-11-05T20:16:51.542196Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"random.seed(1001)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"WVGu2AkyE2xI","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:51.544696Z","iopub.execute_input":"2025-11-05T20:16:51.545024Z","iopub.status.idle":"2025-11-05T20:16:51.606107Z","shell.execute_reply.started":"2025-11-05T20:16:51.545008Z","shell.execute_reply":"2025-11-05T20:16:51.605205Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"1. Dataset","metadata":{"id":"tMaFpTrUm7mt"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rnw2wHtNmsu4","outputId":"5a97c3a3-6e02-4e01-93ef-6cc861e2ceac","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:51.607577Z","iopub.execute_input":"2025-11-05T20:16:51.607861Z","iopub.status.idle":"2025-11-05T20:16:52.115417Z","shell.execute_reply.started":"2025-11-05T20:16:51.607835Z","shell.execute_reply":"2025-11-05T20:16:52.114545Z"}},"outputs":[{"name":"stdout","text":"--2025-11-05 20:16:51--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: ‘input.txt’\n\ninput.txt           100%[===================>]   1.06M  6.24MB/s    in 0.2s    \n\n2025-11-05 20:16:52 (6.24 MB/s) - ‘input.txt’ saved [1115394/1115394]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# read text file\nwith open('input.txt', 'r') as file:\n  text = file.read()\ntext[:100]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4Aa2gORc0pzz","outputId":"49aac0e6-22fa-4873-8765-4d09c1b3fea3","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.116692Z","iopub.execute_input":"2025-11-05T20:16:52.116983Z","iopub.status.idle":"2025-11-05T20:16:52.127119Z","shell.execute_reply.started":"2025-11-05T20:16:52.116960Z","shell.execute_reply":"2025-11-05T20:16:52.126354Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"len(text)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbkoSXRz1O_l","outputId":"23cfc786-c9f7-4b40-d00f-e42ed39cd163","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.127976Z","iopub.execute_input":"2025-11-05T20:16:52.128177Z","iopub.status.idle":"2025-11-05T20:16:52.141266Z","shell.execute_reply.started":"2025-11-05T20:16:52.128163Z","shell.execute_reply":"2025-11-05T20:16:52.140456Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1115394"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# convert text to [ids] according to vocab\nvocab = sorted(list(set(text)))\nprint(vocab)\n\nid_map = {c : i for (i,c) in enumerate(vocab)}\nid_map_reverse = {i : c for (i,c) in enumerate(vocab)}\nprint(id_map)\n\ndef encode(text):\n  \"\"\"\n    [chars] -> [ids]\n  \"\"\"\n  return [id_map[c] for c in text]\n\ndef decode(ids):\n  \"\"\"\n    [ids] -> string\n  \"\"\"\n  return ''.join(id_map_reverse[id] for id in ids)\n\nprint(decode(encode(\"hello\")) == \"hello\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZJZX9HF1gnH","outputId":"420117ee-c45d-4918-e9b5-2fedcf93a0cb","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.142042Z","iopub.execute_input":"2025-11-05T20:16:52.142247Z","iopub.status.idle":"2025-11-05T20:16:52.167953Z","shell.execute_reply.started":"2025-11-05T20:16:52.142224Z","shell.execute_reply":"2025-11-05T20:16:52.167179Z"}},"outputs":[{"name":"stdout","text":"['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\nTrue\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# train, val set\ntrain = text[:math.floor(0.9*len(text))]\ntest = text[math.floor(0.9*len(text)):]\n\nprint(f\"train size: {len(train)}, test size: {len(test)}\")\n\ndef fetch_batch(mode, batch_size, block_size):\n  if mode=='train':\n    dataset = train\n  else:\n    dataset = test\n  batch_indices = [random.randint(0, len(dataset)-(block_size+1)) for _ in range(0, batch_size)]\n  x = torch.stack([torch.tensor(encode(dataset[index:index+block_size])) for index in batch_indices])\n  y = torch.stack([torch.tensor(encode(dataset[index+1:index+block_size+1])) for index in batch_indices])\n  return x,y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esfpe5Wm__XY","outputId":"0de1e97f-c88a-46b9-dfc0-67fc9b904ed7","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.170439Z","iopub.execute_input":"2025-11-05T20:16:52.170791Z","iopub.status.idle":"2025-11-05T20:16:52.189051Z","shell.execute_reply.started":"2025-11-05T20:16:52.170770Z","shell.execute_reply":"2025-11-05T20:16:52.188261Z"}},"outputs":[{"name":"stdout","text":"train size: 1003854, test size: 111540\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Model architecture\nclass Bigram(nn.Module):\n  def __init__(self, n_vocab):\n    super().__init__()\n    self.embedding_table = nn.Embedding(n_vocab, n_vocab)\n    self.criterion = nn.CrossEntropyLoss() # takes logits as input, needs logits as <everything packed up> x #classes and target variables as ids\n\n  def forward(self, x, y=None):\n    logits = self.embedding_table(x)\n    #print(logits.shape)\n    n_batches, block_size, n_classes = logits.shape\n    logits_temp = logits.view(n_batches*block_size, n_classes)\n    if y == None:\n      return logits, None\n\n    y = y.view(n_batches*block_size)\n    loss = self.criterion(logits_temp, y)\n    return logits, loss\n\n  def generate_next_token(self, x):\n    logits,_ = self(x)\n    # last timestep generated\n    logits = logits[:,-1,:] # shape = batches, score over vocab size\n    prob = torch.softmax(logits, dim=1)\n\n    # top p sampling\n    pred = torch.multinomial(prob, num_samples=1)\n\n    return pred\n\n  def generate(self, x, max_tokens):\n    for i in range(max_tokens):\n      next_word = self.generate_next_token(x)\n      x = torch.cat((x, next_word), dim=1) # increase block size\n    return x\n\n","metadata":{"id":"1Y4M5ehX38W-","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.189787Z","iopub.execute_input":"2025-11-05T20:16:52.190045Z","iopub.status.idle":"2025-11-05T20:16:52.204654Z","shell.execute_reply.started":"2025-11-05T20:16:52.190024Z","shell.execute_reply":"2025-11-05T20:16:52.203770Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# model obj + optimizer\nmodel = Bigram(len(vocab))\n# move model to device\nmodel = model.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)","metadata":{"id":"wMRVzfCs_BvL","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:16:52.205456Z","iopub.execute_input":"2025-11-05T20:16:52.205692Z","iopub.status.idle":"2025-11-05T20:16:54.858447Z","shell.execute_reply.started":"2025-11-05T20:16:52.205677Z","shell.execute_reply":"2025-11-05T20:16:54.857684Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# generation without training\nx = torch.ones((1,1), dtype=torch.long).to(device)\nprint(decode(model.generate(x,100)[0].tolist()))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"N8CQIM0W0zN-","outputId":"85974434-da6c-42df-df7a-e3c31ceee5f4","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:23:59.304793Z","iopub.execute_input":"2025-11-05T20:23:59.305163Z","iopub.status.idle":"2025-11-05T20:23:59.742775Z","shell.execute_reply.started":"2025-11-05T20:23:59.305135Z","shell.execute_reply":"2025-11-05T20:23:59.741934Z"}},"outputs":[{"name":"stdout","text":" t:aH MhfF?XigbqDDXlK;rZ n\nGusM?ZcaKEZytF&MCeZewiAOcl OUJGT?m\ndr3JlKZNOaCbrXk,tjWMtMCfm&mSjqAyDozrE h\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"@torch.no_grad()\ndef performance_measure(batch_size, block_size, n_iters):\n  losses = {'train':0, 'val':0}\n  model.eval()\n  for mode in ['train', 'val']:\n    for _ in range(n_iters):\n      x,y = fetch_batch(mode, batch_size, block_size)\n      x = x.to(device)\n      y = y.to(device)\n      _, loss = model(x,y)\n      losses[mode] += loss.item()\n\n  model.train()\n  losses['train'] /= n_iters\n  losses['val'] /= n_iters\n  return losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:24:01.832354Z","iopub.execute_input":"2025-11-05T20:24:01.832877Z","iopub.status.idle":"2025-11-05T20:24:01.837985Z","shell.execute_reply.started":"2025-11-05T20:24:01.832853Z","shell.execute_reply":"2025-11-05T20:24:01.837259Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# training loop\nn_iters = 10000\ntest_after_iters = 1000\nfor iters in range(0, n_iters):\n  # fetch random batch of training data tensors\n  x,y = fetch_batch('train',64, 256)\n  # move tensors to device\n  x = x.to(device)\n  y = y.to(device)\n\n  # run on model to get loss\n  logits, loss = model(x, y)\n\n  # backprop on loss\n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n\n  if iters % test_after_iters == 0:\n    losses = performance_measure(64, 256, 200)\n    print(f\"Train loss: {losses['train']}, Val loss: {losses['val']}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"komisIkr_6QV","outputId":"57927c13-892e-452e-9c02-013de24e5db1","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:24:04.027218Z","iopub.execute_input":"2025-11-05T20:24:04.027850Z","iopub.status.idle":"2025-11-05T20:25:56.260001Z","shell.execute_reply.started":"2025-11-05T20:24:04.027829Z","shell.execute_reply":"2025-11-05T20:25:56.259397Z"}},"outputs":[{"name":"stdout","text":"Train loss: 4.638998236656189, Val loss: 4.656174647808075\nTrain loss: 4.217304286956787, Val loss: 4.238060631752014\nTrain loss: 3.8558514380455016, Val loss: 3.8783979868888854\nTrain loss: 3.5514151561260223, Val loss: 3.5738569712638855\nTrain loss: 3.2981827664375305, Val loss: 3.321426645517349\nTrain loss: 3.092572566270828, Val loss: 3.1148242712020875\nTrain loss: 2.9300525987148287, Val loss: 2.953620855808258\nTrain loss: 2.804293156862259, Val loss: 2.827827477455139\nTrain loss: 2.7065053391456604, Val loss: 2.7304836297035218\nTrain loss: 2.635009207725525, Val loss: 2.6589745545387267\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# generation after training 10k iters\nx = torch.ones((1,1), dtype=torch.long).to(device)\nprint(decode(model.generate(x,100)[0].tolist()))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7v_89QOUybyh","outputId":"0986e39e-44f6-4ca6-9579-cdb1f1e29988","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T20:26:26.208215Z","iopub.execute_input":"2025-11-05T20:26:26.208922Z","iopub.status.idle":"2025-11-05T20:26:26.243154Z","shell.execute_reply.started":"2025-11-05T20:26:26.208894Z","shell.execute_reply":"2025-11-05T20:26:26.242322Z"}},"outputs":[{"name":"stdout","text":" rek nsun\n:\nVIVorversthor ins,.\nA's\nzzarsaHURICoDWhe INGLIOL's oy tinckekend is.\nyandufind g rinXimol\n","output_type":"stream"}],"execution_count":16}]}